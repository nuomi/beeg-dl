#!/usr/bin/env python


import re, urllib2, pickle, sys
import argparse
import os, time


pageurl_regex = re.compile('http://beeg.com\/\d+')
mp4url_regex = re.compile('http://.+\.mp4')
datafile = 'ret.pk'
ret = []

def extract():

    pageurls = []
    vidzurls = []

    for i in range(2):
        html_src = urllib2.urlopen('http://beeg.com/section/home/'+str(i)+'/').read() 
        matches = pageurl_regex.findall(html_src) 
        pageurls.extend(set(matches))

    for pageurl in pageurls:
        print('looking into '+ pageurl+ '...')
        html_src = urllib2.urlopen(pageurl).read()
        matches = mp4url_regex.findall(html_src)
        vidzurls.extend(set(matches))
        print("\t\tfound "+ str(len(matches)))
    
    pickle.dump(set(vidzurls), open(datafile,'w'))

def downloadOne(opener, url, filename):
    count = 0
    step  = 16*1024
    downloading = True
    success = False
    while (not(success)) and downloading:
        try:
            Err = ""
            netfile = opener.open(url)
            filesize = float(netfile.info()['Content-Length'])
            
            if os.path.exists(filename) and os.path.isfile(filename):
                count = os.path.getsize(filename)

            print count,"of",filesize , "downloaded."

            if count >= filesize:
                downloading = False
                success = True
                netfile.close()
                return

            if os.path.exists(filename) and os.path.isfile(filename):
                netfile.close()
                req = urllib2.Request(url)
                print "file downloading at byte: ", count
                req.add_header("Range","bytes=%s-" % (count))
                netfile = opener.open(req)

            if (downloading):
                nextbyte = netfile.read(step)
                outfile = open(filename, "ab")
                outfile.write(nextbyte)
                count += step
                while (len(nextbyte)>0) and downloading:
                    nextbyte = netfile.read(step)
                    outfile.write(nextbyte)
                    count += len(nextbyte)
                success = True
        except IOError, e:
            print e
            Err=("Download error, retrying in a few seconds: "+str(e))
            try:
                netfile.close()
            except Exception:
                pass
            time.sleep(8)




def downloadAll():
    vidzurls = pickle.load(open(datafile))
    opener = urllib2.build_opener();

    for vidzurl in vidzurls:
        print("download "+ vidzurl)
        filename = os.path.basename(vidzurl)
        downloadOne(opener, vidzurl, filename)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='download vidz from beeg.com')
    parser.add_argument('-u',  action='store_true',
                      help='get vidz urls, and save them to a data file.')

    parser.add_argument('-d', action='store_true',
                      help='download vidz according to data file.')

    parser.add_argument('-a', action='store_false',
                      help='get urls and download them.(default)')

    args = vars(parser.parse_args())

    if args['u']:
        extract()
        sys.exit()

    elif args['d']:
        downloadAll()
        sys.exit()

    else:
        extract()
        downloadAll()
        sys.exit()
